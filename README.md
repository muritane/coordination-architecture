# A Core Theory of Bounded Cognition and Action

*(Interface, Reachability, Continuity, Viability, and Scale-Separated Correction)*

---

## 0. Orientation

This document presents a **boundary theory of cognition and action** for bounded agents operating under irreversible constraints.

It is **not**:

* a learning algorithm,
* an optimization method,
* a moral or political theory,
* or a theory of rational choice.

It is a **structural account** of what action, redesign, and meaning *can be* for agents whose cognition, execution, and feedback are physically constrained.

The theory is agent-first. Population- and institutional-scale phenomena are treated as **derivative correction mechanisms**, not extensions of individual agency.

---

## 1. The Core Problem

Bounded agents must act in environments that are:

* partially observable,
* noisy and non-stationary,
* costly or unsafe to explore,
* temporally delayed,
* mediated by other agents, institutions, or protocols.

Crucially:

* Many failures are **locally irreversible** along an agent’s realized trajectory.
* Some errors cannot be explored, undone, amortized, or delegated.
* Some alternative actions or redesigns cannot even be *expressed* because the required representational or execution interfaces are unavailable.

At the same time, agents are embedded in populations and institutions that:

* preserve memory externally,
* absorb losses statistically,
* experiment via replacement rather than continuity.

This creates a structural asymmetry between:

* **agent-local action and redesign**, and
* **population-level correction and persistence**.

**The central question** is therefore:

> How can bounded agents act, learn, and redesign themselves when action is locally irreversible, execution is delayed, interfaces are limited, and some forms of correction are possible only by abandoning agent-level continuity?

---

## 2. Irreducible Constraints

### 2.1 Local Irreversibility of Action

Any pipeline from:

*world → perception → representation → authorization → execution*

is many-to-one and locally non-invertible.

Executing an action commits the agent to one realized transition while collapsing alternative futures.

Greater precision does not remove this loss; it **stabilizes** it.

Local irreversibility applies:

* to individual agents,
* along realized trajectories,
* regardless of population-level redundancy or recovery.

---

### 2.2 Executable Continuity Constraint

> **An agent can reach a future state if and only if there exists a causally continuous sequence of physically realizable intermediate states connecting the present to that future.**

Signals propagate at finite speed. Computation, coordination, learning, communication, and physical movement all require nonzero time and energy.

No increase in intention, preference, or intelligence can eliminate latency.

Population-level mechanisms (replacement, selection, institutional reform) do not violate this constraint; they operate by **abandoning continuity at the agent level**.

---

### 2.3 Interface Reachability Constraint

Beyond continuity, agents face a stricter limitation:

> **An action or redesign is possible only if it is expressible using interfaces the agent already possesses.**

An agent cannot:

* act in a language it cannot parse,
* compute on a non-existent instruction set,
* coordinate while rejecting the underlying protocol,
* redesign itself using representations it cannot execute.

Interfaces may be physically real yet **not agent-identifiable in time**, due to:

* latency,
* abstraction depth,
* representational limits,
* bounded precision and attention.

Physical measurability in principle does not imply executable reachability under bounded resources.

---

## 3. Interfaces as the Unit of Agency

### 3.1 Interfaces

Agency is exercised not over abstract action sets, but over **interfaces**:

* execution interfaces (muscle, actuators, CPUs),
* representational interfaces (languages, symbols, models),
* coordination interfaces (protocols, laws, procedures),
* observational interfaces (sensors, instruments, measurement pipelines).

An interface specifies:

* admissible inputs and outputs,
* sequencing and timing constraints,
* error handling (or lack thereof),
* versioned validity conditions.

Rejecting an interface annihilates the action space it defines.

---

### 3.2 Authorization

Authorization is not moral permission. It is **interface conformance**.

An action is authorized if and only if it:

* conforms to the currently valid interface specification,
* at the correct version,
* within declared scope and time bounds.

Exactness guarantees syntactic validity only.

Semantic correctness and global optimality are never guaranteed under bounded precision and abstraction.

---

## 4. Cognition as Interface Management

Under these constraints, cognition is not belief manipulation or preference satisfaction.

> **Cognition is the maintenance, compression, and revision of executable interfaces such that critical feedback and redesign processes remain reachable within viability bounds.**

Interface preservation precedes goal pursuit.

Abstraction is unavoidable, but every abstraction trades:

* flexibility for efficiency,
* adaptability for scale,
* optionality for stability.

---

## 5. Viability Across Scales

### 5.1 Agent-Local Viability

> **An agent is viable over a horizon H if and only if its critical execution, authorization, feedback, and redesign interfaces remain executable within physical time, energy, and precision bounds throughout H.**

Loss of any critical interface collapses agent-local viability, regardless of intent, intelligence, or correctness.

---

### 5.2 Population and Institutional Viability

At larger scales, systems preserve function through:

* redundancy,
* replacement of agents,
* externalized memory,
* statistical selection.

These mechanisms preserve **system-level persistence**, not agent-level continuity.

Agent-local redesign and population-level correction are distinct processes with distinct failure modes and ethical implications.

---

### 5.3 Criticality and Discoverability

Interfaces are *critical* when their loss collapses viability.

However, criticality is often:

* discovered only ex post,
* identifiable only at population scale,
* inferable only through irreversible loss.

Agents may rationally preserve non-critical interfaces while compressing critical ones, until failure reveals the error.

---

## 6. Feedback, Latency, and Causality

### 6.1 Time-Bounded Feedback

Feedback loops are viable only if they close within physical decay windows:

* before resources dissipate,
* before commitments become irreversible,
* before semantic drift exceeds correction capacity.

Delayed feedback is not weaker feedback; beyond a threshold, it is **causally irrelevant**.

---

### 6.2 Waiting

Waiting is a real action:

> **Waiting is a temporal commitment that preserves interface eligibility while deferring control, without initiating a new causal chain.**

Institutional processes are serialized, multi-agent execution pipelines with bounded throughput. Their delays are structural latency constraints, not resistance or intent.

---

### 6.3 Prohibition of Action-at-a-Distance

> **Any model that assumes influence without a continuous, executable chain of interactions is acausal.**

Population-level effects emerge from aggregated local interactions, not from unmediated influence.

---

## 7. Meaning as a Derived Interface Property

Meaning is not intrinsic to symbols.

> **A representation is meaningful if and only if it preserves or extends the set of reachable, executable, viability-preserving actions for an agent under uncertainty.**

Representations gain meaning by:

* reducing uncertainty relevant to action,
* compressing environmental regularities into executable latents,
* supporting policy selection and redesign.

Semantic drift becomes dangerous when representational compression outpaces executable redesign.

When redesign latency exceeds drift accumulation, correction occurs via **replacement rather than continuity-preserving revision**.

---

## 8. Phase Structure of Interface-Constrained Systems

Interface-constrained systems tend to exhibit overlapping phases:

### Phase 1 — Scaffolded Exploration

* Preserve degrees of freedom.
* Act within safe, reversible interfaces.
* Accumulate latent structure.

### Phase 2 — Interface Compression

* Identify invariants.
* Encode executable, versioned interfaces.
* Collapse distinctions into equivalence classes.

### Phase 3 — Scaled Execution

* Execute cheaply and repeatably.
* Accept reduced adaptability.
* Monitor latency and semantic drift.

### Phase 4 — Redesign or Replacement

Triggered when:

* errors cluster,
* feedback loops fail to close,
* redesign latency exceeds viability bounds.

Outcomes:

* **Redesign**, if executable continuity is preserved.
* **Replacement**, if correction requires abandoning continuity.

---

## 9. Governance and Loss Allocation

Interfaces encode values by determining:

* which transitions are admissible,
* for how long,
* and under whose authority.

Structural legitimacy requires:

* public access to interface specifications,
* explicit versioning and scope,
* symmetric exposure to irreversible risk,
* clarity about whether failure is borne by agents or populations.

Many governance failures are interface failures masked by population-level buffering.

---

## 10. Core Synthesis

> **Bounded cognition is the management of executable interfaces under irreversible action, finite latency, and constrained redesign.**
>
> **Representations are meaningful only insofar as they preserve viable action.**
>
> **When redesign cannot keep pace with drift or error, correction occurs through replacement at larger scales.**

This framework explains:

* why abstraction is unavoidable,
* why exactness enables scale yet accelerates failure,
* why efficiency creates brittleness,
* why exit and redesign are hard locally but common globally,
* why authority over interfaces determines who absorbs irreversible loss.

---

## 11. Continuity Externalization and Loss Allocation

### 11.1 Continuity Is Conserved, Not Localized

Agent-local continuity is not self-sufficient. Across time horizons exceeding individual lifetimes, continuity is preserved through **externalized interfaces**, including:

* shared representations (language, calendars, records),
* institutional memory (science, law, medicine),
* material infrastructure (tools, energy systems, supply chains),
* population-level persistence mechanisms.

Individual agents remain viable over extended horizons precisely because continuity is **distributed across populations and artifacts**, rather than preserved locally.

Conversely, population- and infrastructure-level continuity depends on the replaceability of individual agents. Continuity therefore flows *bidirectionally* across scales.

---

### 11.2 Irreversible Loss and Allocation Under Failure

Under irreversible action and bounded redesign, **loss cannot be eliminated**, only allocated.

Whenever redesign latency exceeds error accumulation, irreversible loss must be absorbed by some combination of:

* individual agents,
* populations,
* infrastructures,
* or replaceable substrates.

This allocation is not optional. It is structurally enforced by irreversibility and bounded interfaces.

---

### 11.3 Dynamic Loss Triage

Loss allocation is **contextual and dynamic**, not hierarchical or intrinsic.

Under normal operation:

* continuity is mutually reinforcing across agents, populations, and infrastructure.

Under failure:

* continuity is **triaged**, routing irreversible loss toward components with higher replaceability or faster recovery.

This triage is determined by:

* available interfaces,
* redesign latency,
* replaceability profiles,
* coupling between failure modes.

The direction of loss allocation may change over time as interfaces evolve.

---

### 11.4 Interfaces Encode Loss Routing

Interfaces do not merely enable action; they **encode how irreversible loss propagates** when action fails.

Examples include:

* medical research infrastructures that absorb experimental risk to preserve population health,
* calendars and shared temporal references that preserve coordination across generations,
* institutional procedures that buffer individual failure through redundancy,
* mechanical and synthetic agents designed for high replaceability.

Interface governance therefore implicitly specifies:

* which agents absorb loss first,
* which forms of continuity are preserved,
* and which failures are deferred, externalized, or concentrated.

---

### 11.5 Continuity Expansion and Decoupling

Long-term system viability depends on expanding the space of reachable continuity-preserving configurations by:

* externalizing memory and capability,
* reducing correlated failure surfaces,
* increasing substrate replaceability,
* and extending continuity beyond single environments or agent classes.

Such expansion does not eliminate constraints, but **reshapes loss allocation**, reducing existential coupling and increasing redesign reachability.

---

### 11.6 Synthesis

> Continuity in multi-agent systems is conserved through externalization across agents, populations, and infrastructures.
> Under irreversible failure and bounded redesign, loss must be dynamically allocated.
> Interfaces determine how loss propagates and where continuity is preserved.

This completes the framework’s account of viability across scales without introducing optimization criteria, moral hierarchy, or policy prescriptions.

---

## Scaffold Preservation Principle

> **Any system that compresses interfaces faster than it preserves either agent-local redesign capacity or population-level replacement capacity will eventually lose the ability to adapt.**

---

## Scope

This theory applies to biological, artificial, institutional, and hybrid systems wherever action requires exact execution under irreversible abstraction, bounded interfaces, finite time, and selective replacement.

---

## License

Creative Commons Attribution 4.0 International (CC BY 4.0).
