# A Core Theory of Action for Bounded Agents

*(Interface, Reachability, Continuity, and Population–Constrained Revision)*

---

## 1. The Problem

Bounded agents must act in environments that are:

* partially observable,
* noisy and non-stationary,
* costly or unsafe to explore,
* temporally delayed,
* and often mediated by other agents or institutions.

Many failures are **irreversible along the agent’s local trajectory**. Errors cannot always be explored, undone, amortized, or delegated. Crucially, agents often cannot even *express* alternative actions or redesigns because the required representational or execution interfaces are unavailable.

At the same time, agents rarely exist in isolation. They are embedded in **populations, institutions, and lineages** that can absorb losses, preserve external memory, and experiment through replacement rather than continuity.

**The central question is therefore:**

> How can bounded agents act and redesign themselves over time when action is locally irreversible, execution is delayed, interfaces are limited, redesign must proceed through physically executable intermediate states, *and some forms of correction are possible only at population or institutional scales*?

---

## 2. Irreducible Constraints

### 2.1 Local Irreversibility of Action

Any pipeline from

*world → perception → representation → authorization → execution*

is many-to-one and locally non-invertible. Executing an action commits the agent to one realized transition while collapsing alternative futures.

Exact execution does not remove this loss; it stabilizes it.

Local irreversibility applies to individual agents and individual executions, regardless of population-level redundancy.

---

### 2.2 Executable Continuity Constraint

All agents are subject to a **continuity constraint**:

> No agent can reach a future state unless there exists a causally continuous sequence of physically realizable intermediate states connecting the present to that future.

Signals propagate at finite speed. Computation, coordination, learning, communication, and physical movement all require nonzero time and energy. Increasing intention, will, or preference cannot eliminate latency.

Population-level correction mechanisms (replacement, selection, institutional reform) do not violate this constraint; they operate by **abandoning continuity at the agent level**.

---

### 2.3 Interface Reachability Constraint

Beyond continuity, agents face a stricter constraint:

> A redesign or action is possible only if it is expressible using interfaces the agent already possesses.

An agent cannot:

* act in a language it cannot parse,
* compute on a non-existent instruction set,
* communicate while rejecting the underlying protocol,
* redesign itself using representations it cannot execute.

Interfaces may be physically real yet **not agent-identifiable in time**, due to latency, abstraction, or representational limits. Physical measurability in principle does not imply executable identifiability under bounded resources.

---

## 3. Interfaces, Protocols, and Authorization

### 3.1 Interfaces as the Unit of Agency

Agency is exercised not over abstract action sets, but over **interfaces**:

* execution interfaces (muscle, actuators, CPUs),
* representational interfaces (languages, symbols, models),
* coordination interfaces (protocols, laws, procedures),
* observational interfaces (sensors, instruments, measurement pipelines).

An interface defines:

* admissible inputs and outputs,
* sequencing and timing constraints,
* error handling (or lack thereof),
* versioned validity conditions.

Rejecting an interface annihilates the action space it defines.

---

### 3.2 Authorization as Interface Conformance

Authorization is not permission in the moral sense. It is **interface-level validity**.

An action is authorized if and only if:

* it conforms to the currently valid interface specification,
* at the correct version,
* within declared scope and time bounds.

Exactness guarantees syntactic validity only. Semantic correctness is never guaranteed globally under bounded precision and abstraction.

---

## 4. Viability Across Scales

### 4.1 Agent-Local Viability

At the agent level:

> **A system is viable over a horizon H if and only if its critical execution, authorization, feedback, and redesign interfaces remain executable within their physical time, energy, and precision bounds throughout H.**

Loss of any critical interface collapses agent-local viability, regardless of intent or preference.

---

### 4.2 Population and Institutional Viability

At larger scales, systems may preserve function despite individual failure through:

* redundancy,
* replacement of agents,
* externalized memory (records, models, tools),
* statistical selection over populations.

These mechanisms **do not preserve agent-local continuity**. They trade individual viability for population-level persistence.

Agent-local redesign and population-level correction are distinct mechanisms with different failure modes and ethical implications.

---

### 4.3 Criticality and Discoverability

Interfaces are deemed *critical* when their loss collapses viability.

However, criticality is often:

* discovered only ex post,
* identifiable only at population scale,
* or inferable only through irreversible loss.

Thus, agents may rationally preserve non-critical interfaces while compressing critical ones, until failure reveals the mistake.

---

## 5. Feedback, Latency, and Causality

### 5.1 Time-Bounded Feedback

Feedback loops are viable only if they close within their physical decay windows:

* before resources dissipate,
* before commitments become irreversible,
* before semantic drift exceeds correction capacity.

Delayed feedback is not weaker feedback; beyond a threshold, it is causally irrelevant.

---

### 5.2 Waiting and Institutional Delay

Waiting is a real action:

> Waiting is a temporal commitment that preserves interface eligibility while deferring control, without initiating a new causal chain.

Institutional processes are serialized, multi-agent execution pipelines with bounded throughput. Their delays are structural latency constraints, not resistance or intention.

---

### 5.3 Prohibition of Action-at-a-Distance

> Any model that assumes influence without a continuous, executable chain of interactions is acausal.

Population-level effects emerge from aggregated local interactions, not from influence without transmission.

---

## 6. Precision, Semantic Drift, and Replacement

Interfaces guarantee local correctness only. Under bounded precision:

* truncation errors accumulate,
* abstractions drift semantically,
* failures appear globally while execution remains locally valid.

Semantic drift may be tolerable locally yet catastrophic at scale. When redesign latency exceeds drift accumulation, correction occurs not through redesign but through **replacement of agents or interfaces**.

Technological evolution (e.g., changes in instruction sets or measurement standards) often proceeds by extinction and substitution rather than continuity-preserving upgrade.

---

## 7. Phase Structure of Interface-Constrained Systems

### Phase 1: Scaffolded Exploration

* Preserve degrees of freedom.
* Act only within safe, executable interfaces.
* Accumulate latent structure.

### Phase 2: Interface Compression

* Identify stable invariants.
* Encode executable, versioned interfaces.
* Collapse distinctions into equivalence classes.

### Phase 3: Scaled Execution

* Execute cheaply and repeatably.
* Accept reduced adaptability.
* Monitor for semantic drift and latency overruns.

### Phase 4: Redesign or Replacement

Triggered when:

* errors cluster,
* interfaces no longer close feedback loops,
* redesign latency exceeds viability bounds.

Outcomes:

* **Redesign** if executable continuity is preserved.
* **Replacement** if correction requires abandoning continuity.

---

## 8. Governance, Coordination, and Loss Allocation

All interfaces encode values by determining:

* which transitions are admissible,
* for how long,
* and under whose authority.

Legitimate governance requires:

* public access to interface specifications,
* explicit versioning and scope,
* symmetric exposure to irreversible risk,
* clarity about whether failure is borne by agents or populations.

Governance failures are interface failures, often masked by population-level buffering.

---

## 9. Core Synthesis

> **Intelligent action is the phase-appropriate execution, revision, or replacement of versioned interfaces, under continuity, reachability, and population constraints, chosen so that critical feedback and redesign processes remain executable at the relevant scale.**

This framework explains:

* why abstraction is unavoidable,
* why exactness enables scale yet accelerates failure,
* why efficiency creates brittleness,
* why exit and redesign are hard locally but common globally,
* and why authority over interfaces determines who absorbs irreversible loss.

---

## Scaffold Preservation Principle

Any system that compresses interfaces faster than it preserves either:

* agent-local redesign capacity, or
* population-level replacement capacity,

will eventually lose the ability to adapt.

---

## Scope

This theory applies to biological, artificial, institutional, and hybrid systems wherever action requires exact execution under irreversible abstraction, bounded interfaces, finite time, and selective replacement.

It is a boundary logic, not a learning algorithm, optimization method, or moral theory.

---

## License

Creative Commons Attribution 4.0 International (CC BY 4.0).
