# Causal Reasoning Boundaries  
## A Structural Account of Horizon-Limited Causality in Executable Systems

---

## Status and Intent

This document defines **causal reasoning boundaries**: structural limits on how far causal chains remain *load-bearing* for an agent or group during execution.

These boundaries are **not**:
- intelligence limits,
- moral failings,
- education gaps,
- personality traits,
- or indicators of care or sincerity.

They are **executional limits**: points at which causality ceases to bind action and is replaced by interpretation, narrative, or judgment.

The perspective here is **architectural**, not psychological.  
The question is not *what people believe*, but *what continues to constrain action* once feedback is delayed, diffused, or displaced.

---

## Core Claim

> Causality does not disappear when feedback is delayed.  
> **It ceases to be load-bearing.**

When causal links fall outside an agent’s executable horizon, they are no longer enforced at runtime. At that point, reasoning defaults to interpretive frames that preserve coherence without binding future cost.

---

## The Executable Causal Chain

A **causal chain is executable** only while all of the following hold:

- the agent can *locate themselves* on the chain,
- the next action is identifiable,
- cost attribution is plausible,
- feedback is expected within a tolerable horizon,
- and failure remains attributable.

When these conditions fail, the chain may still exist *in theory*, but it no longer governs behavior.

---

## The Causal Horizon

### Definition

The **causal horizon** is the maximum distance—temporal, social, or structural—over which an agent can maintain causality as a binding constraint on action.

Beyond this horizon:
- causality becomes descriptive rather than prescriptive,
- responsibility diffuses,
- and interpretation replaces execution.

The horizon is not fixed. It varies by:
- role,
- exposure to irreversible failure,
- coordination pressure,
- and system coupling.

---

## Compiled Causality (Inside the Horizon)

Certain causal chains are universally maintained because they are:

- single-step,
- immediate,
- low-risk,
- invariant,
- and repeatedly reinforced.

Examples:
- flipping a light switch,
- opening a tap,
- removing a bottle cap before drinking.

These are not *reasoned about*.  
They are **compiled execution habits**.

Inside this regime:
- no interpretation is required,
- no justification is offered,
- no narrative is invoked.

This is not deep causal understanding.  
It is **successful compression under tight feedback**.

---

## The Horizon Cliff

### Definition

The **horizon cliff** is the point at which feedback moves just far enough away that causal enforcement collapses.

Common displacements:
- delayed feedback (weeks, months, years),
- distributed responsibility,
- multi-agent coupling,
- reputational rather than physical cost,
- system-level rather than local failure.

At the cliff:
- causality does not weaken gradually,
- it **drops out abruptly**.

Agents do not experience this as loss of causality.  
They experience it as a **frame change**.

---

## Horizon-Induced Frame Switching

When the causal horizon is exceeded, agents switch frames automatically:

- from **execution** → **interpretation**
- from **constraint** → **consideration**
- from **risk** → **tradeoff**
- from **failure** → **unfortunate outcome**

This switch is:
- non-deliberate,
- socially reinforced,
- and rarely visible to the agent performing it.

Once switched, causal reasoning may persist rhetorically but is no longer binding.

---

## Interpretation as a Stabilization Strategy

Interpretation replaces execution because it:

1. **Restores agency without action**  
   One can hold a view without incurring cost.

2. **Preserves social legibility**  
   Interpretations can be shared, debated, and rewarded.

3. **Defers accountability**  
   Outcomes are displaced into the future or onto the system.

Interpretation is not irrational.  
It is **cheaper** than maintaining long causal chains under uncertainty.

---

## Causal Offloading

Beyond the horizon, causality is often offloaded to:

- institutions (“the system will handle it”),
- processes (“there are safeguards”),
- collectives (“we decided together”),
- or time (“we’ll see how it plays out”).

This offloading is rarely explicit.  
It manifests as confidence without exposure.

---

## Individual vs Structural Causality

A common failure mode is to treat causal breakdown as a moral or cognitive defect.

In reality:
- individuals may be locally rational,
- while the system accumulates global risk.

Causal reasoning boundaries explain how:
- competent agents,
- acting in good faith,
- produce late, expensive failures.

---

## The Minority That Maintains Long Causality

Some agents continue to treat causality as binding beyond the horizon.

Common features:
- exposure to irreversible loss,
- responsibility without narrative cover,
- roles where failure is terminal rather than educational,
- repeated experience with drift.

For these agents:
- causality remains structural, not contextual,
- delayed feedback does not relax constraints.

They experience horizon collapse in others as:
- denial,
- negligence,
- or magical thinking.

This is usually a **regime mismatch**, not a disagreement.

---

## System Survival and Asymmetric Load

Most systems function because:
- a minority maintains long-horizon causality,
- while the majority operates within short horizons.

This creates an asymmetric load:
- long-horizon agents absorb cognitive and social cost,
- short-horizon agents gain flexibility and comfort.

The system appears stable until:
- coupling increases,
- slack decreases,
- or accumulated drift crosses a threshold.

Failures then appear sudden, despite being causally continuous.

---

## Diagnostic Questions

To detect horizon-limited causality, ask:

- “Who bears the cost if this fails later?”
- “When will failure become visible?”
- “Is anyone refusing this path on causal grounds alone?”
- “What happens if interpretation is wrong?”

If these questions trigger discomfort rather than redesign, the horizon has likely been exceeded.

---

## Relationship to Executional Literacies

Causal reasoning boundaries underlie multiple executional failures:

- **Constraint literacy collapse** → constraints treated as negotiable
- **Horizon literacy collapse** → expired solutions defended
- **Frame literacy collapse** → interpretive answers to executional questions
- **Risk literacy collapse** → averages optimized despite ruin risk
- **Coordination literacy collapse** → intent blamed for structural failure

Causality has not vanished in these cases.  
It has been **rendered non-binding**.

---

## Closing

Causal chains do not require belief.  
They require **maintenance under delay**.

Most agents maintain causality only where:
- feedback is immediate,
- responsibility is local,
- and failure is survivable.

Beyond that boundary, interpretation takes over—not as error, but as adaptation.

Systems that survive increasing coupling and constraint are those that:
- recognize causal reasoning boundaries,
- protect agents who maintain long causality,
- and redesign before interpretation becomes the only remaining move.

Causality is always there.  
The question is only whether it still governs action.
